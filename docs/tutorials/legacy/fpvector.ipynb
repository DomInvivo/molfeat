{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized Fingerprint transformer classes\n",
    "\n",
    "Aside from the generic molecular transformer classes, two specialized fingerprint vectors are also provided\n",
    "\n",
    "- **`FPVecTransformer`** is a wrapper around the original transformer that takes the parameters of the featurizer directly as input. A parameter called `kind` needs to be provided to specify which fingerprints should be initialized. \n",
    "\n",
    "- **`FPVecFilteredTransformer`** add an additional feature that consist of checking non zeros occurence at each fingerprint position, as well as uniqueness of their values, then filtered out position not meeting some user-defined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamol as dm\n",
    "import random\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "\n",
    "# set printing option\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "# set random list\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "data = dm.data.freesolv().sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'radius': 3,\n",
       " 'nBits': 1024,\n",
       " 'invariants': [],\n",
       " 'fromAtoms': [],\n",
       " 'useChirality': False,\n",
       " 'useBondTypes': False,\n",
       " 'useFeatures': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from molfeat.trans.fp import FPVecTransformer\n",
    "from molfeat.trans.fp import FPVecFilteredTransformer\n",
    "\n",
    "trans1 = FPVecTransformer(kind=\"fcfp:6\", length=1024, useBondTypes=False)\n",
    "trans1.featurizer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the parent MoleculeTransformer class, **you can copy and serialize these featurizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPVecTransformer(kind=\"fcfp:6\", length=1024, dtype=np.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'molfeat.trans.fp.FPVecTransformer': {'n_jobs': 1,\n",
       "  'dtype': numpy.float32,\n",
       "  'verbose': False,\n",
       "  'useBondTypes': False,\n",
       "  'kind': 'fcfp:6',\n",
       "  'length': 1024}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molfeat.trans.fp.FPVecTransformer:\n",
      "  dtype: !!python/name:numpy.float32 ''\n",
      "  kind: fcfp:6\n",
      "  length: 1024\n",
      "  n_jobs: 1\n",
      "  useBondTypes: false\n",
      "  verbose: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trans1.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,) 1024\n"
     ]
    }
   ],
   "source": [
    "X = trans1(data[\"smiles\"], enforce_dtype=True)[0]\n",
    "print(X.shape, len(trans1.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the effect of filtering out bits that are very rarely activate with `FPVecFilteredTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans2 = FPVecFilteredTransformer(\n",
    "    kind=\"fcfp:6\", length=1024, useBondTypes=False, del_invariant=False, occ_threshold=0\n",
    ")\n",
    "# the default behaviour should be the same as with the original FPVecTransformer\n",
    "X2 = trans2(data[\"smiles\"], enforce_dtype=True)[0]\n",
    "np.all(X == X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we want bits non activated at least 1% of the time or invariant columns to be removed.\n",
    "trans2 = FPVecFilteredTransformer(\n",
    "    kind=\"fcfp:6\", length=1024, useBondTypes=False, del_invariant=True, occ_threshold=0.01\n",
    ")\n",
    "\n",
    "# Since we have not fitted the transformer yet\n",
    "# the behaviour would be the same as we do not have the fit parameter to located invariant in the training set\n",
    "X2 = trans2(data[\"smiles\"], enforce_dtype=True)[0]\n",
    "np.all(X == X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219,) 219\n"
     ]
    }
   ],
   "source": [
    "# Let's try to fit the fingerprint first instead\n",
    "# we will use a random sample from freesolve that is a bit larger and might not overlap with out test set\n",
    "\n",
    "train_data = dm.data.freesolv().sample(n=600)[\"smiles\"]\n",
    "trans2.fit(train_data)\n",
    "X2 = trans2(data[\"smiles\"], enforce_dtype=True)[0]\n",
    "print(X2.shape, len(trans2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,) 2048\n"
     ]
    }
   ],
   "source": [
    "# Parallelization by setting n_jobs\n",
    "trans3 = FPVecTransformer(kind=\"pharm2D\", length=2048, n_jobs=4)\n",
    "X3 = trans3(data[\"smiles\"], enforce_dtype=True)[0]\n",
    "print(X3.shape, len(trans3.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing grid search with the specialized fingerprint transformers\n",
    "\n",
    "We will work on the same task again, the goal here is to search over an hyper-parameter space of the pipeline, which would include our featurizer parameters.\n",
    "\n",
    "This requires having a featurizer compatible with scikit-learn (some gymnastic to get this to work seemingly).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dm.data.freesolv()\n",
    "X, y = df[\"smiles\"], df[\"expt\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('feat', FPVecTransformer(kind='rdkit')),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'feat__kind': ['fcfp:6', 'rdkit', 'pharm2D'],\n",
       "                         'feat__length': [512, 1024],\n",
       "                         'rf__n_estimators': [100, 500]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = FPVecTransformer(kind=\"rdkit\")\n",
    "pipe = Pipeline(\n",
    "    [(\"feat\", feat), (\"scaler\", StandardScaler()), (\"rf\", RandomForestRegressor(n_estimators=100))]\n",
    ")\n",
    "\n",
    "param_grid = dict(\n",
    "    feat__kind=[\"fcfp:6\", \"rdkit\", \"pharm2D\"], feat__length=[512, 1024], rf__n_estimators=[100, 500]\n",
    ")\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405142255762323"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feat', FPVecTransformer(kind='rdkit', length=1024)),\n",
       "                ('scaler', StandardScaler()), ('rf', RandomForestRegressor())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c96cf3fad8b1d12df3e2b8c5ffc5fe9bd56815b225365ae05bb8eb0616dbb51"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

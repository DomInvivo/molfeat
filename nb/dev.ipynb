{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import molfeat\n",
    "import datamol as dm\n",
    "from molfeat.store.modelcard import ModelInfo\n",
    "\n",
    "# for back compat and model transfer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Card"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maccs\n",
    "maccs = ModelInfo(\n",
    "    name = \"maccs\",\n",
    "    inputs = \"smiles\",\n",
    "    type=\"hand-crafted\",\n",
    "    group=\"rdkit\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"MACCS keys are 166-bit 2D structure fingerprints that are commonly used for the measure of molecular similarity. They described the presence of key features in molecular graphs\",\n",
    "    representation=\"vector\",\n",
    "    require_3D=False,\n",
    "    tags = [\"maccs\", \"fixed\", \"2D\", \"binary\", 'rdkit'],\n",
    "    authors= [\"MDL Information Systems\"],\n",
    "    reference = \"https://doi.org/10.1021/ci010132r\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import datamol as dm\n",
      "from molfeat.trans import FPVecTransformer\n",
      "data = dm.freesolv().iloc[:100]\n",
      "transformer = FPVecTransformer(kind='maccs')\n",
      "features = transformer(data[\"smiles\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(maccs.usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamol as dm\n",
    "from molfeat.trans.fp import FPVecTransformer\n",
    "data = dm.freesolv()\n",
    "transformer = FPVecTransformer(kind=\"maccs\")\n",
    "features = transformer(data[\"smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECFP\n",
    "ecfp = ModelInfo(\n",
    "    name = \"ecfp\",\n",
    "    inputs = \"smiles\",\n",
    "    type=\"hashed\",\n",
    "    group=\"fp\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"Extended-connectivity fingerprints (ECFPs) are a family of circular fingerprints that are commonly used for the measure of molecular similarity. They are based on the connectivity of atoms in molecular graphs.\",\n",
    "    representation=\"vector\",\n",
    "    require_3D=False,\n",
    "    tags = [\"ECFP\", \"fixed\", \"2D\", \"binary\", 'rdkit', \"Morgan\"],\n",
    "    authors= [\"David Rogers\", \"Mathew Hahn\"],\n",
    "    reference = \"https://doi.org/10.1021/ci100050t\" # the doi is better here.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgllife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "# an example of supervised GIN model\n",
    "gin_contextpred = ModelInfo(\n",
    "    name = \"gin_supervised_contextpred\",\n",
    "    inputs = \"smiles\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"dgllife\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"GIN neural network model pre-trained with supervised learning and context prediction on molecules from ChEMBL.\",\n",
    "    representation=\"graph\",\n",
    "    require_3D=False,\n",
    "    tags = [\"GIN\", \"dgl\", \"pytorch\", \"graph\"],\n",
    "    authors= [\"Weihua Hu\", \"Bowen Liu\", \"Joseph Gomes\", \"Marinka Zitnik\", \"Percy Liang\", \"Vijay Pande\", \"Jure Leskovec\"],\n",
    "    reference = \"https://arxiv.org/abs/1905.12265\" \n",
    ")\n",
    "gin_contextpred_model = dgllife.model.load_pretrained('gin_supervised_contextpred')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of JTVAE model on zinc\n",
    "graphormer = ModelInfo(\n",
    "    name = \"pcqm4mv2_graphormer_base\",\n",
    "    inputs = \"smiles\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"graphormer\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"Pretrained Graph Transformer on PCQM4Mv2 Homo-Lumo energy gap prediction using 2D molecular graphs.\",\n",
    "    representation=\"graph\",\n",
    "    require_3D=False,\n",
    "    tags = [\"Graphormer\", \"PCQM4Mv2\", \"graph\", \"pytorch\", \"Microsoft\"],\n",
    "    authors= ['Chengxuan Ying',\n",
    "                'Tianle Cai',\n",
    "                'Shengjie Luo',\n",
    "                'Shuxin Zheng',\n",
    "                'Guolin Ke',\n",
    "                'Di He',\n",
    "                'Yanming Shen',\n",
    "                'Tie-Yan Liu'\n",
    "    ],\n",
    "    reference = \"https://arxiv.org/abs/2106.05234\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import datamol as dm\n",
      "from molfeat.trans.pretrained import GraphormerTransformer\n",
      "data = dm.freesolv().iloc[:100]\n",
      "transformer = GraphormerTransformer(kind='pcqm4mv2_graphormer_base')\n",
      "features = transformer(data[\"smiles\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graphormer.usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading JTVAE_ZINC_no_kl_pre_trained.pth from https://data.dgl.ai/pre_trained/jtvae_ZINC_no_kl.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "# an example of JTVAE model on zinc\n",
    "jtvae = ModelInfo(\n",
    "    name = \"jtvae_zinc_no_kl\",\n",
    "    inputs = \"smiles\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"dgllife\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"A JTVAE pre-trained on ZINC for molecule generation, without KL regularization\",\n",
    "    representation=\"other\",\n",
    "    require_3D=False,\n",
    "    tags = [\"JTNN\", \"JTVAE\", \"dgl\", \"pytorch\", \"junction-tree\", \"graph\"],\n",
    "    authors= [\"Wengong Jin\", \"Regina Barzilay\", \"Tommi Jaakkola\"],\n",
    "    reference = \"https://arxiv.org/abs/1802.04364v4\" \n",
    ")\n",
    "# we load the jtvae model from dgllife pretrained to register on the store\n",
    "jtvae_model = dgllife.model.load_pretrained('JTVAE_ZINC_no_kl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import datamol as dm\n",
      "from molfeat.trans.pretrained import PretrainedDGLTransformer\n",
      "data = dm.freesolv().iloc[:100]\n",
      "transformer = PretrainedDGLTransformer(kind='jtvae_zinc_no_kl')\n",
      "features = transformer(data[\"smiles\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jtvae.usage())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molfeat.store.modelstore import ModelStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ModelStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelInfo(name='gin_supervised_contextpred', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with supervised learning and context prediction on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 2, 19, 45, 57, 641213), sha256sum='5e23bc0926f85117456ee670aea6da91cedf25e1fe4a28c806b852c7b4ea5ceb'),\n",
       " ModelInfo(name='jtvae_zinc_no_kl', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='A JTVAE pre-trained on ZINC for molecule generation, without KL regularization', representation='other', require_3D=False, tags=['JTNN', 'JTVAE', 'dgl', 'pytorch', 'junction-tree', 'graph'], authors=['Wengong Jin', 'Regina Barzilay', 'Tommi Jaakkola'], reference='https://arxiv.org/abs/1802.04364v4', created_at=datetime.datetime(2023, 2, 2, 19, 46, 0, 894894), sha256sum='e6f0877ae3718143c35b7e8f49280bc8d93fc02d416e7e67567fed97a98a6242'),\n",
       " ModelInfo(name='pcqm4mv2_graphormer_base', inputs='smiles', type='pretrained', version=0, group='graphormer', submitter='Datamol', description='Pretrained Graph Transformer on PCQM4Mv2 Homo-Lumo energy gap prediction using 2D molecular graphs.', representation='graph', require_3D=False, tags=['Graphormer', 'PCQM4Mv2', 'graph', 'pytorch', 'Microsoft'], authors=['Chengxuan Ying', 'Tianle Cai', 'Shengjie Luo', 'Shuxin Zheng', 'Guolin Ke', 'Di He', 'Yanming Shen', 'Tie-Yan Liu'], reference='https://arxiv.org/abs/2106.05234', created_at=datetime.datetime(2023, 2, 2, 19, 45, 59, 816180), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1'),\n",
       " ModelInfo(name='maccs', inputs='smiles', type='hand-crafted', version=0, group='rdkit', submitter='Datamol', description='MACCS keys are 166-bit 2D structure fingerprints that are commonly used for the measure of molecular similarity. They described the presence of key features in molecular graphs', representation='vector', require_3D=False, tags=['maccs', 'fixed', '2D', 'binary', 'rdkit'], authors=['MDL Information Systems'], reference='https://doi.org/10.1021/ci010132r', created_at=datetime.datetime(2023, 2, 2, 19, 45, 51, 653035), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.available_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174cf1caeefa4ca7b45aedff41227193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 19:51:31.644 | INFO     | molfeat.store.modelstore:register:124 - Successfuly registered model maccs !\n"
     ]
    }
   ],
   "source": [
    "# maccs is not a pretrained fingerpint\n",
    "# we have no model to save\n",
    "store.register(maccs, model=None, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.exists(maccs, check_remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2984ab667254c99bf28f4c7639d78bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/7.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 19:51:40.118 | INFO     | molfeat.store.modelstore:register:124 - Successfuly registered model gin_supervised_contextpred !\n"
     ]
    }
   ],
   "source": [
    "store.register(gin_contextpred, model=gin_contextpred_model, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2914cc4af98b41fb9c5027ca2531c000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 19:51:55.866 | INFO     | molfeat.store.modelstore:register:124 - Successfuly registered model jtvae_zinc_no_kl !\n"
     ]
    }
   ],
   "source": [
    "store.register(jtvae, model=jtvae_model, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb323836d3d403abecc50edf36be1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 19:51:57.991 | INFO     | molfeat.store.modelstore:register:124 - Successfuly registered model pcqm4mv2_graphormer_base !\n"
     ]
    }
   ],
   "source": [
    "# we don't need to save the graphormer model specifically\n",
    "store.register(graphormer, model=None, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors:\n",
      "- Weihua Hu\n",
      "- Bowen Liu\n",
      "- Joseph Gomes\n",
      "- Marinka Zitnik\n",
      "- Percy Liang\n",
      "- Vijay Pande\n",
      "- Jure Leskovec\n",
      "created_at: 2023-02-02 19:51:17.228390\n",
      "description: GIN neural network model pre-trained with supervised learning and context\n",
      "  prediction on molecules from ChEMBL.\n",
      "group: dgllife\n",
      "inputs: smiles\n",
      "name: gin_supervised_contextpred\n",
      "reference: https://arxiv.org/abs/1905.12265\n",
      "representation: graph\n",
      "require_3D: false\n",
      "sha256sum: 72dc062936b78b515ed5d0989f909ab7612496d698415d73826b974c9171504a\n",
      "submitter: Datamol\n",
      "tags:\n",
      "- GIN\n",
      "- dgl\n",
      "- pytorch\n",
      "- graph\n",
      "type: pretrained\n",
      "version: 0\n",
      "=======\n",
      "authors:\n",
      "- Wengong Jin\n",
      "- Regina Barzilay\n",
      "- Tommi Jaakkola\n",
      "created_at: 2023-02-02 19:51:20.468939\n",
      "description: A JTVAE pre-trained on ZINC for molecule generation, without KL regularization\n",
      "group: dgllife\n",
      "inputs: smiles\n",
      "name: jtvae_zinc_no_kl\n",
      "reference: https://arxiv.org/abs/1802.04364v4\n",
      "representation: other\n",
      "require_3D: false\n",
      "sha256sum: eab8ecb8a7542a8cdf97410cb27f72aaf374fefef6a1f53642cc5b310cf2b7f6\n",
      "submitter: Datamol\n",
      "tags:\n",
      "- JTNN\n",
      "- JTVAE\n",
      "- dgl\n",
      "- pytorch\n",
      "- junction-tree\n",
      "- graph\n",
      "type: pretrained\n",
      "version: 0\n",
      "=======\n",
      "authors:\n",
      "- Chengxuan Ying\n",
      "- Tianle Cai\n",
      "- Shengjie Luo\n",
      "- Shuxin Zheng\n",
      "- Guolin Ke\n",
      "- Di He\n",
      "- Yanming Shen\n",
      "- Tie-Yan Liu\n",
      "created_at: 2023-02-02 19:51:19.330147\n",
      "description: Pretrained Graph Transformer on PCQM4Mv2 Homo-Lumo energy gap prediction\n",
      "  using 2D molecular graphs.\n",
      "group: graphormer\n",
      "inputs: smiles\n",
      "name: pcqm4mv2_graphormer_base\n",
      "reference: https://arxiv.org/abs/2106.05234\n",
      "representation: graph\n",
      "require_3D: false\n",
      "sha256sum: 9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1\n",
      "submitter: Datamol\n",
      "tags:\n",
      "- Graphormer\n",
      "- PCQM4Mv2\n",
      "- graph\n",
      "- pytorch\n",
      "- Microsoft\n",
      "type: pretrained\n",
      "version: 0\n",
      "=======\n",
      "authors:\n",
      "- MDL Information Systems\n",
      "created_at: 2023-02-02 19:51:10.688803\n",
      "description: MACCS keys are 166-bit 2D structure fingerprints that are commonly used\n",
      "  for the measure of molecular similarity. They described the presence of key features\n",
      "  in molecular graphs\n",
      "group: rdkit\n",
      "inputs: smiles\n",
      "name: maccs\n",
      "reference: https://doi.org/10.1021/ci010132r\n",
      "representation: vector\n",
      "require_3D: false\n",
      "sha256sum: 9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1\n",
      "submitter: Datamol\n",
      "tags:\n",
      "- maccs\n",
      "- fixed\n",
      "- 2D\n",
      "- binary\n",
      "- rdkit\n",
      "type: hand-crafted\n",
      "version: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "print(\"=======\\n\".join(yaml.dump(model.dict()) for model in store.available_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we don't have this model saved\n",
    "store.search(ecfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelInfo(name='maccs', inputs='smiles', type='hand-crafted', version=0, group='rdkit', submitter='Datamol', description='MACCS keys are 166-bit 2D structure fingerprints that are commonly used for the measure of molecular similarity. They described the presence of key features in molecular graphs', representation='vector', require_3D=False, tags=['maccs', 'fixed', '2D', 'binary', 'rdkit'], authors=['MDL Information Systems'], reference='https://doi.org/10.1021/ci010132r', created_at=datetime.datetime(2023, 2, 2, 19, 51, 10, 688803), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do have this model saved\n",
    "store.search(maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelInfo(name='jtvae_zinc_no_kl', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='A JTVAE pre-trained on ZINC for molecule generation, without KL regularization', representation='other', require_3D=False, tags=['JTNN', 'JTVAE', 'dgl', 'pytorch', 'junction-tree', 'graph'], authors=['Wengong Jin', 'Regina Barzilay', 'Tommi Jaakkola'], reference='https://arxiv.org/abs/1802.04364v4', created_at=datetime.datetime(2023, 2, 2, 19, 51, 20, 468939), sha256sum='eab8ecb8a7542a8cdf97410cb27f72aaf374fefef6a1f53642cc5b310cf2b7f6')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(name=\"jtvae_zinc_no_kl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_model, maccs_info = store.load(\"maccs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_model # empty because it's a hand-crafted fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(name='maccs', inputs='smiles', type='hand-crafted', version=0, group='rdkit', submitter='Datamol', description='MACCS keys are 166-bit 2D structure fingerprints that are commonly used for the measure of molecular similarity. They described the presence of key features in molecular graphs', representation='vector', require_3D=False, tags=['maccs', 'fixed', '2D', 'binary', 'rdkit'], authors=['MDL Information Systems'], reference='https://doi.org/10.1021/ci010132r', created_at=datetime.datetime(2023, 2, 2, 18, 14, 6, 571706), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maccs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108dc675e5c343c9967d93d79a05a996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee46dd89d2e4d2e954a0079026a2518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/7.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gin_reloaded_model, gin_reloaded_info = store.load(\"gin_supervised_contextpred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GIN(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (node_embeddings): ModuleList(\n",
       "    (0): Embedding(120, 300)\n",
       "    (1): Embedding(3, 300)\n",
       "  )\n",
       "  (gnn_layers): ModuleList(\n",
       "    (0): GINLayer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (edge_embeddings): ModuleList(\n",
       "        (0): Embedding(6, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): GINLayer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (edge_embeddings): ModuleList(\n",
       "        (0): Embedding(6, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): GINLayer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (edge_embeddings): ModuleList(\n",
       "        (0): Embedding(6, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): GINLayer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (edge_embeddings): ModuleList(\n",
       "        (0): Embedding(6, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): GINLayer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (edge_embeddings): ModuleList(\n",
       "        (0): Embedding(6, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin_reloaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import datamol as dm\n",
      "from molfeat.trans.pretrained import PretrainedDGLTransformer\n",
      "data = dm.freesolv().iloc[:100]\n",
      "transformer = PretrainedDGLTransformer(kind='gin_supervised_contextpred')\n",
      "features = transformer(data[\"smiles\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gin_reloaded_info.usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.0801709e-03, -1.5467817e-01, -1.2526581e-01, ...,\n",
       "         2.3464283e-01, -7.5401053e-02,  2.0824190e-02],\n",
       "       [-7.0198812e-04, -8.1730559e-02, -6.2045324e-01, ...,\n",
       "        -2.3603138e-01,  7.3010635e-01,  3.8331217e-01],\n",
       "       [ 2.7388150e-02,  1.8647036e-01, -2.4399137e-01, ...,\n",
       "         5.7929408e-02,  1.7175178e-01, -1.7541242e-01],\n",
       "       ...,\n",
       "       [ 2.5242649e-02,  1.7176455e-01, -1.3434565e-01, ...,\n",
       "         1.2988050e-01,  2.0930676e-01, -1.2900873e-01],\n",
       "       [-2.7901845e-03, -1.3657156e-01,  4.3633554e-02, ...,\n",
       "         2.1721300e-01,  1.0626764e-01,  1.2404752e-01],\n",
       "       [-1.5046312e-02,  4.4183634e-02,  1.9645907e-01, ...,\n",
       "         4.8413888e-02, -2.6770476e-01,  2.4833913e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(gin_reloaded_info.usage())\n",
    "features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molfeat.store.modelstore import ModelStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ModelStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemberta_card = store.search(name=\"DeepChem-ChemBERTa-77M-MLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import datamol as dm\n",
      "from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n",
      "data = dm.freesolv().iloc[:100]\n",
      "transformer = PretrainedHFTransformer(kind='DeepChem-ChemBERTa-77M-MLM', notation='smiles')\n",
      "features = transformer(data[\"smiles\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chemberta_card[0].usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/manu/Library/Caches/molfeat/DeepChem-ChemBERTa-77M-MLM/model.save were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /Users/manu/Library/Caches/molfeat/DeepChem-ChemBERTa-77M-MLM/model.save and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b481404f6f402cb03542614ea482d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2881e189bdc4cf3b91782474d1f2aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datamol as dm\n",
    "from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n",
    "data = dm.freesolv().iloc[:100]\n",
    "transformer = PretrainedHFTransformer(kind='DeepChem-ChemBERTa-77M-MLM', notation='smiles')\n",
    "features = transformer(data[\"smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08768422, -0.07157033, -0.04022325, ...,  0.10310469,\n",
       "         0.16929244, -0.13035022],\n",
       "       [ 0.10688866,  0.10707027,  0.23671532, ...,  0.01356442,\n",
       "         0.09901753, -0.18887427],\n",
       "       [ 0.18590733, -0.3194937 , -0.16546208, ...,  0.16675094,\n",
       "         0.12800565, -0.1350749 ],\n",
       "       ...,\n",
       "       [-0.00189916, -0.3090676 , -0.11365637, ...,  0.17380431,\n",
       "        -0.08730147, -0.4555515 ],\n",
       "       [ 0.18555567, -0.1301071 , -0.17172852, ...,  0.08563311,\n",
       "        -0.00947405, -0.3082643 ],\n",
       "       [-0.10831349, -0.08913019, -0.02071786, ...,  0.12807605,\n",
       "         0.2750607 , -0.11662877]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd64925fe6617865d410306d2b64fa69b44b63a36aad85fd11f7d4e4dc7609f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
